---
title: Fruiting trees and human logarithms
date: 2021-02-01T07:31:59Z
draft: false
math: true
---

Regardless of how much maths you know or do, you have probably heard about logarithms. Perhaps especially in the context of the "logarithmic scale" which is sometimes used to show data in graphs, for example to track the growth of a pandemic. In my job I use logarithms quite a lot, but there is still something slightly baffling about them, so I thought I'd devote this post to logarithms: what they are in terms of a general maths tool, but also how they - interestingly - turn up in human behaviour sometimes. How, and why?

Perhaps the easiest way to intuitively think about what a logarithm is, is that it is the opposite (or "inverse") of exponential growth. And by exponential growth I mean the kind of growth you get when you have a number of something, for example a number of people infected with a disease, and that number gets repeatedly scaled up by the same multiplication over and over, for example because each infected person infects a number of other people within a certain time, and then the same thing happens again and again. This pandemic example is only a little too familiar though, so let's switch to a nicer one: the number of branches or fruits in a growing tree, Click in the image to grow a tree, click again to grow a new one. 

{{< rawhtml >}}
    <iframe src="tree.html" width="100%" height="310" style="border:none"></iframe>
{{< /rawhtml >}}
[TODO: stop drawing once the tree isn't in the viewport (see [here](https://www.javascripttutorial.net/dom/css/check-if-an-element-is-visible-in-the-viewport/)) + adapt to less wide windows?]

In the animation above, each new (sometimes fruit-bearing) branch gives rise to about three smaller branches, each smaller branch in turn giving rise to about three even smaller branches, and so on. So after one branching step, there are about three branches, after two branching steps 3 x 3 = 9 branches, then 3 x 3 x 3 = 27, then 81, 243, 729, and so on. Repeated upscaling by the same multiplication, in other words exponential growth. Or not quite, because in practice I have limited the maximum number of branching steps in the animation, to not have your computer crash from excessive horticulture. That's the hallmark of exponential growth really - it quickly explodes out of control:

![Animation showing increasing ranges of an exponential growth curve.](exp.gif)
[TODO: Add axis labels.]

And the corresponding hallmark of the logarithm, then, is that it brings this explosion back in check, by effectively instead just telling you for how long the growth has been going on, which tends to be a more manageable number. In other words, if you take the number of branches in the tree and you apply the right logarithm to that number, then you get back the number of branching steps since the tree started growing. So the logarithm of 3 is one, the logarithm of 9 is two, and the logarithms of 27, 81, 243, 729, are three, four, five, and six, and so on. Below is the same exponential growth again, and to the right of it is the corresponding logarithmic curve.

![The same animation as just above (top left), but also showing (bottom left) the same exponential growth in a logarithmic axis, i.e. a straight line, and (top right) the corresponding logarithmic growth, with the same values as in the exponential curve, just x and y flipped.](expandlog.gif)
[TODO: Add axis labels.]

The graph on the bottom shows the same exponential growth curve as in the graph above it, but now shown in a logarithmic scale instead. What this means in practice is that a value y on that curve is drawn not at a height y over the zero line, as in a normal plot, but instead at a height that is the logarithm of the value y. And since the curve we are plotting is a pure exponential growth, the logarithm of it is equal to the number of branching steps, which of course is also what is on the x axis, so it all comes back as a completely straight line. Anytime you see a straight line increase in a plot with a logarithmic y scale, you know that you are seeing exponential growth. The second thing to note in the illustration above is the little "3" in the \\(\log_3\\) above the logarithmic curve - this means that we aren't showing just any logarithm, but the logarithm of "base 3". In this case, this is "the right logarithm", since the multiplication factor in the tree's growth was 3, meaning that we get back the number of branching steps correctly for our specific tree. But regardless of "base", all logarithms have the basic looks of the curve to the right above: it increases quickly first, and then the rate of increase just gets slower and slower. So precisely the opposite of exponential growth, as we said.

That's enough of the basics I think, so let's move on to the interesting thing I mentioned earlier, that logarithms sometimes turn up in human behaviour. By this I mean that human behaviour can sometimes be well described mathematically using logarithms. Probably the most famous example of this is *Hick's Law*, named after the psychologist William Edmund Hick. In the early 1950s, he was doing experiments where participants learned to associate a number of different stimuli with different responses - in his case lamps with buttons. So the task for a participant in Hick's experiment was to look at a number of lamps, between one and ten of them, while keeping fingers ready on the same number of buttons, and when one of the lamps came on, the participant had to press the button corresponding to that lamp as quickly as possible. And what Hick found was that the response time - the time between lamp illumination and button press - increased logarithmically with the number of response alternatives:

![A figure with two logarithmic curves closely fitting data points from four different data sets.](hickfig.png)
*Figure from [Hick's 1952 paper](https://journals.sagepub.com/doi/10.1080/17470215208416600) (behind a paywall), showing logarithmic growth of response times for a few different datasets. Hick's Law is sometimes called the Hick-Hyman Law instead, also crediting Ray Hyman, who did [similar work](https://psycnet.apa.org/record/1954-00412-001) at about the same time.*

Lots of experiments of the same general nature as Hick's have been carried out in the decades since Hick's paper, and quite often people have found the same logarithmic increase of response time with the number of response alternatives. Some of the experiments have been quite substantially different from the original speeded stimulus-response type of task. For example, [it has been shown](https://doi.org/10.1080/10447318.2017.1306940) that when a driver looks away from the road toward a familiar graphical user interface to press a button on a touch screen, the time needed to land the eyes on the correct button scales logarithmically with the number of buttons on the screen; in other words in this case the decision is about which button to look at. In [another study](https://doi.org/10.1016/j.jmp.2009.09.002), on decision-making in a more slow-paced setting, participants observed a number of growing stacks of blocks (kind of like Tetris), and were to respond as soon as they felt that they knew which stack was growing more quickly than the others. Again the logarithmic Hick's Law pattern appeared, as a function of the number of stacks being observed. So the general, recurring idea is that the time needed to decide on the correct thing to do grows logarithmically with the number of things we are deciding between. 

If you want to, you can have a go yourself at a Hick-like task below. Your mission, should you choose to accept it, is to wait for a fruit to appear at the top of the little screen, and then move your cursor to the white circle corresponding to that fruit as quickly as you possibly can. To start a trial, place your cursor in the middle white circle. (If you are using a touch screen rather than a mouse, to start a trial tap the middle circle then keep your finger over it - no cheating!). Before each trial the different fruits that may be shown are highlighted - that's your varying number of response alternatives. By default the maximum is four alternatives, but you can toggle the maximum to eight if you want to challenge yourself further. I am not sure how it will work out for you, but for me, once I have practiced enough to know pretty well where all the fruits are, my response times (plotted at the bottom of the screen as you go) do look quite logarithmic. If you want to restart the game after having practiced for a while, just do a long click/touch anywhere in the screen.

(TODO: Insert Hicks fruit game; TODO: Add 4/8 toggle.)

So why on earth is there a logarithm here? Hick himself had his own thoughts about this, and he couched them in terms of *information theory*, which was a new and very hot topic at the time. In fact, he named his 1952 paper *"On the rate of gain of information"*. He considered that if you are a participant looking at his display of lamps, with one lamp just having lit up, you are in the process of acquiring information about what button to press, and that information can be measured in bits, where each bit is either a zero or a one, just the way we still to this day measure information stored in and transmitted between computers. Here he is, W. E. Hick, smoking his pipe (as one does) while making adjustments to his apparatus (lamps to the left, buttons at his hands):

![A black and white photograph of W. E. Hick, smoking a pipe while applying a screwdriver to one of a number of push buttons mounted with electrical wiring on a wooden board. Next to it is another board, tilted at an angle, on which a number of lamps are mounted and wired. ](hick_and_apparatus.png)

*Photo from [this paper](https://psycnet.apa.org/doi/10.1037/1093-4510.7.1.85).*

If Hick knows which button is the correct one, and wants to send you a message to say which one it is, then if there are only two buttons to choose between, then he can send just a single bit where 0 means one lamp and 1 means the other. If there are more lamps, the maximum possible number he needs to transmit is larger, so he needs to send a longer string of bits. And how does the number of bits grow with the maximum size of the number he is sending? Well logarithmically of course. The reason for this is that again we get back to the idea of a tree:

(TODO: interactive tree plot - height chosen by mouse Y, target fruit chosen by mouse X)

In other words, Hick's suggestion was that the brain might be dealing with decision situations by way of a kind of divide and conquer, iteratively splitting the pool of decision alternatives into smaller and smaller parts. Intuitively, in the fruit game you played above, upon seeing the banana your brain could be going through a process like: "I know the banana is in the right half. I know that it is in the lower part of the right half. I know it is..." In other words, the "rate of gain of information" that Hick was after can be thought of as "how quick is the brain at repeatedly dividing the space of decision options into smaller parts?" 

So is this what the brain actually does? Almost certainly not. Already Hick himself actually had his own doubts, because he argued that if the underlying process was really just a number of divisions of the pool of alternatives, then response times should take on a limited number of at least reasonably well-defined values, all multiples of the time it takes to do one "division", but he couldn't see any such patterns in his data. Other critiques were raised already by Hick's contemporaries (see for example [this review paper](https://doi.org/10.1080%2F17470218.2017.1322622), which also provides a nice discussion on the circumstances under which Hick's Law has been found to break down), and nowadays I think few people would argue that tree search is a good description for what happens in the brain during multiple choice decisions.

If we interpret the "divide and conquer" idea a bit more loosely though, it isn't too far off from our current best theories of what the brain does in these situations. These theories suggest that the brain does divide the decision task, not in the form of a tree search but rather by letting a different team of neurons deal with each decision option separately. So for each possible decision, there is a group of neurons who are trying to judge whether "their" decision is the good one or not, by adding up evidence in favour of this decision option, sent to them from other parts of the brain. When the summed-up evidence of one of the groups of neurons reaches a "decision threshold", the brain goes ahead, and you choose that option. Below you can run a simulation of this process, with two, four, six, and eight different decision options. To the left you see the "target fruit" in the given trial of the simulated experiment, and to the right are plots of the neural evidence buildup, one group for each available button. The incoming evidence is noisy, but on average the rate of evidence buildup is faster for the correct response option than for the others. At the bottom you can see a similar plot to the one in the game you played above, showing the response time, and highlighting incorrect responses in red - from when the noise in an "incorrect" evidence buildup happened to be large enough to get all the way to the decision threshold. 

(TODO: simulation)

*This simulation is of the simplest possible model in [this paper](https://psycnet.apa.org/doi/10.1037/0033-295X.108.3.550) (without lateral inhibition or leakage).*

As you can see, the logarithmic pattern appears - so this simulation "explains" Hick's law. There is something a little sneaky about the explanation though: if you look closely, you can see that the decision threshold actually isn't the same everywhere. The reason for this has to do with noise, and with errors. The lower we set the threshold, the higher the risk that an incorrect group of neurons reaches threshold by chance before the correct one, and the larger the number of such incorrect groups of neurons we have, the higher this risk is. In other words, if we want to maintain a consistent low rate of errors, we need to set higher thresholds when considering larger numbers of decision options. In the simulation above, I set the threshold so as to achieve a rate of errors of around 10 %. 

In other words, according to current neuroscientific theory, Hick's law is due to a form of speed-accuracy tradeoff, where the brain lets different teams of neurons add up evidence in parallel to reach a quick decision, but to keep the risk of random slip-ups manageable the brain increases the required burden of evidence when there are more such teams running in parallel. The statistical nature of this decision process leads to the progressively flattening, logarithmic curve of response times.

This is relatively satisfying, I think, although possibly not quite as mathematically elegant as the tree-search explanation, which explains more directly why there is a logarithm specifically. ... There are two questions I think you may very sensibly ask in response to this explanation: ... first, is rate of errors consistent? ... maybe in Hick's experiment... but yes typically response times go down... Can be explained by assuming a slightly more advanced goal for the speed-accuracy tradeoff, not only to keep errors consistent, but to ... (not exactly sure how to phrase this)...? ... However, even with this type of assumption, the response times still come out looking logarithmic.... 

 (Kohl et al 2019; Usher and McClelland, 2001; Vul et al, 2014; Tajima et al, 2019)... Same as above, but now adapting the starting point to be further from the decision threshold... 

... summary... logarithms is about branching... and we saw that Hick's law is logarithmic, but by a different kind of branching where a decision gets parallelised, and keeping ...


